% !TEX root = ../hmodel.tex
\section{Discussion}
\label{sec:discussion}
\input{fig/motiontypes/item.tex}

\AT{Sentence from CONCERTO: ``The correspondences now contribute only a small computational cost to each iteration, comparing very favourably with ICP, where a 
closest-point operation must be performed on each iteration for each data point.'' For convtrack this is not a problem because it's very cheap, yet we can get a very good fitting model}

\AT{Something about the fact that rather than mentioning thresholds and values and gradients we just provide source code for it?}

% The core investigation in this paper is whether convolutional surfaces are a viable alternative for realtime hand tracking with single-view RBGD sensors. 
% Our hypothesis is that the increased geometry accuracy compared with cylinder models allows for a higher tracking precision without impairing the computational performance of the tracking algorithm.

\TODO{mention no need to re-init $\gg$FPS?}.

\Anastasia{Also, I think it is important to mention that in all the sequences the depth data is downsampled 4 times. Otherwise, the reviewers might say that our tracking looks better because the hand is very close to the sensor. It is close that that it can be seen better}

\Anastasia{Maybe, this goes too far, but we might say that our model calibration has so little degrees of freedom compared to a triangles mesh, that it does not depend on a prior as heavily as triangular mesh-based systems. Those systems cannot work without a prior - too many degrees of freedom. And a prior means acquiring a database of hands. Not any research team can accomplish that.}

\Anastasia{More on calibration. I do not remember exactly, but I think to calibrate a triangular mesh one has to solve a huge off-line optimization problem. Our calibration can run as fast as tracking (I think so, we will see when I implement it will C++}.

\Anastasia{The calibration is still not perfect, there is several components to it, centers position, initial transformations, joint limits and PCA (initial transformations, joint limits and PCA seem to be similar for all humans, but in a perfect world we could try to optimize for all of them).  Every time I improve one of these components, the tracking is getting better. I can see that there is still room for improvement. (Because our data source is not good and our calibration is just the first attempt.) But every improvement in calibration leads to a better tracking. At least for the slow motion, data quality is not the limit yet.}

\Anastasia{Also, I think we could mention that our system can be optimized to 120 FPS ... on Linux ... maybe. The tracking quality degrades with speed of motion, that is with number of frames per some ``quantity of motion``. With faster frame rate the system will definitely get better.}

\Anastasia{We can stress again that we do not have re-initialization not because it is somehow fundamentally impossible in our method, but because we want to demonstrate how good our tracking is. It basically only brakes in limitation cases (fast motion, other objects, rotating thumb, out of sensor range.) For that we could totally add some powerful re-initialization to make the system even more robust.}

