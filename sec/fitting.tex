\section{Calibration}
Our calibration procedure tailors a convolutional model to a specific user from a set of $N$ 3D measurements $\{ \depth_1 \dots \depth_N \}$ of the user's hand in different poses. Multiple measurements are necessary for a number of reasons: (1) in monocular acquisition the model acquired from a single view is highly incomplete; (2) it is not possible to understand the kinematic behavior by analyzing static datasets; (3) the redundancy of information across frames allows us to improve fitting precision. In our research we have experimented with datasets $\{\depth_i\}$ acquired via from multi-view stereo (e.g. \emph{Agisoft Photoscan~\textcopyright}), as well as single RGBD sensor. Our calibration formulation is \todo{very general} and can be readily adapted to either acquisition modalities.

\paragraph{Kinematic Optimization}
While our convolution model is fully specified by sphere positions and radii, most tracking systems, including the one we build upon, parameterize the pose through the specification of a kinematic chain. Every node of the chain is associated with an orthogonal frame $\mathbf{\bar{T}}_k$ according to which local transformations are specified; see~\Figure{posing}. An an example, transformations for the index finger are parameterized so to result in \todo{flexion} (resp. \todo{abduction}) as a rotation around the local $x$ (resp. $y$) axis. In most tracking systems frame origin and axes are manually specified by a 3D modeling artist, and often initialized as identity matrices. While for most articulations such an approximation is somewhat acceptable, it is particularly challenging to select the correct reference frame for the thumb articulation. In the accompanying video \todo{[00:00]}, we clearly show how incorrect initialization of $\mathbf{\bar{T}}$ can be highly detrimental to tracking quality.

\begin{DRAFT}
Therefore in our technique we automatically discover the structure of the kinematic chain from input data. The geometry of the convolution surface is represented by two matrices $\centers$ and $\radii$ respectively containing centers $\ballcenter_i$ and radii $r_i$ along rows. 
\end{DRAFT}

\paragraph{Formulation}
Let us partition our free parameters into two sets $\parposture$ and $\parpose$. 
The vector $\parpose_n$ contains the pose parameters optimally aligning the rest-pose template to the data frame $\depth_n$, (i.e. pose). 
The vector $\parposture$ contains the Euler angles parameterizing the rest-pose transformations $\mathbf{\bar{T}}$ in \Eq{kinematic} (i.e. posture).
% 
Our calibration optimization can then be written as:
\begin{eqnarray}
\argmin_{\parposture, \centers, \radii}
\sum_{n=1}^N 
\sum_{\mathcal{T} \in \termscalib} 
w_\mathcal{T} E_\mathcal{T}(\depth_n, \parpose_n, \parposture, \centers, \radii)
\label{eq:calibration}
\end{eqnarray}
% 
We employ a set of energies $\termscalib$ to balance two different aspects. On one side we would like our model $\model$ to be a good fit to our data, on the other we require each posed model to be a piecewise-rigid posing of a convolution template that is non-degenerate. Our energies $\termscalib$ are:
% 
\begin{description}[labelsep=0em,labelwidth=.4in,labelindent=1cm]
\item[d2m] the data should lie close to our model
\item[m2d] the model should lie close to the data
\item[rigid] convolution elements are posed rigidly
\item[valid] convolution elements should not degenerate
\end{description}
% 
To make this calibration more approachable numerically, we rewrite \Eq{calibration} as an iterative alternating optimization problem:
% 
\begin{eqnarray}
\argmin_{\parposes,\parposture} 
\sum_{n=1}^N 
\sum_{\mathcal{T} \in \termscalib}
w_\mathcal{T} E_\mathcal{T}(\depth_n, \parpose_n, \parposture, \centers, \radii) 
&& \text{(Step 1)}
\label{eq:step1}
\\
\argmin_{\centers, \radii} 
\sum_{n=1}^N 
\sum_{\mathcal{T} \in \termscalib}
w_\mathcal{T} E_\mathcal{T}(\depth_n, \parpose_n, \parposture, \centers, \radii)
&& \text{(Step 2)}
\label{eq:step2}
\end{eqnarray}
% 
In the first step, pose and posture are optimized jointly by fixing the geometry of the template and aligning multiple instances to each frame. The kinematic chain is adjusted by refining the rest-pose transformations $\mathbf{\bar{T}}_k$; note only the rotational portions of $\mathbf{\bar{T}}_k$ are optimized for, as frame translations are inferred from $\skeleton$. In the second step, sphere centers and radii of our convolution model are adjusted, thus altering the rest pose geometry of the convolution surface to better conform to the user.

\subsection{Energies}
We now describe in details the various energies of our optimization. For notational brevity, we gather the parameters of our model as $\pars_n=[\parpose_n, \parposture, \centers, \radii]$.

\paragraph{Data $\rightarrow$ Model}
Every measurement $\point$ in our data frame $\depth_n$ should be explained by our model. Given an operator $\proj_\model$ computing the projection of $\point$ onto the model $\model$, this requirement can be measured by the energy:
% 
\begin{equation}
E_{d2m} = \sum_{p \in \depth_n} \| \point - \proj_{\model(\pars_n)}(\point)\|_2^1
\label{eq:d2m}
\end{equation}
% 
The energy amount to the integral length of ICP correspondence vectors. Note we employ a robust $\ell_1$ norm to make our correspondences resilient to noise and outliers. \TODO{Mention gradients in the appendix? especially for the ones in \Eq{step2}}.



\paragraph{Model $\rightarrow$ Data}
As we are seeking for a model which is \emph{strictly sufficient} to represent our data, we need to ensure that no portion of the model remains unused. The data-to-model term encodes an approximation of the one-sided Hausdorff distance, but this is insufficient in applications where the tracking template is unknown. An approximation of the \emph{symmetric} Hausdorff distance can be obtained by also accounting for model-to-data correspondences:
\begin{equation}
E_{d2m} = \sum_{\point \in \model(\pars_n)} \| \point - \proj_{\depth_n}(\point)\|_2^1
\label{eq:m2d}
\end{equation}
The set of points $\point$ can be obtained by rasterizing our model. Note that the projection operator $\proj_{\depth_n}$ changes according to the type of input data being used. If a multi-view acquisition system is used to acquire a complete point cloud, then the projection operator is similar to the one used for \Eq{d2m}: we build a kd-tree for the point cloud in frame $\depth_n$ and fetch the closest point to $\point$. Conversely, if the data in $\depth_n$ has been obtained through monocular acquisition, then $\proj_{\depth_n}$ computes the 2D projection to the image-space silhouette of the model.



\paragraph{Rigidity}
The consistency energy requires that for every rigid part of the skeleton the distances between every pair of vertices are the same for all the poses. The consistency energy does not apply to elastic parts of hand model.
\Anastasia{To demonstrate rigid parts I could color-code them on the skeleton topology image. The rigid parts are palm, wrist and each finger segment}

\paragraph{Non degeneracy}
This energy ensures that pills do not degenerate into spheres and wedges do not degenerate into pills.
A pill becomes degenerate if one of the spheres is completely inside of another sphere. A wedge becomes degenerate if a sphere is completely inside of the tangent cone of two other spheres. The energy switches on if a pill or a wedge is within a threshold of becoming degenerate and pushes the optimization away.

% \paragraph{Synchronizing rotations energy}
% \AT{This is now obsolete, as we encode common rotation frames for nodes of the kinematic chain} This energy ensures that initial rotations are similar for all the poses. The common initial rotations are computed as described in the section ``Initial Rotations''. The energy minimizes the distance between the current centers and the centers locations with common initial rotations. This energy is very important, because it constraints fingers motion in meaningful way. In the absence of this energy each joint bends in arbitrary direction.

\subsection{Optimization}
Step1: this step is analogous to the one used for real-time tracking\\
Step2: ARAP like solve\\
Step3: simplifying assumption, just use the $\centers$

\begin{DRAFT}
The initial values of the parameters for each pose  $\{[c^0_1 , r^0]$, ..., $[c^0_n, r^0]\}$ are found tracking an input depth sequence with a template hand model globally scaled such that the length of the model hand matches the data.
\end{DRAFT}

\endinput

% The first reason is that we want ensure that the resulting hand model will be able to assume all the poses that a real hand can, or at least the subset of poses for which we have the point clouds.
% The second reason is that the artifacts present in some input point clouds might be compensated by the others, so it is possible to accumulate information this way.
% For fitting we use the same optimization framework as for tracking (in a hope to extend it to fitting \& tracking real time system).
% The main difference is that instead of the joint angles $\theta$, the hand model is parametrized by convolution surface centers locations and radii $[c , r]$.
% \begin{equation*}
% \sigma =\underset{\sigma}{\operatorname{argmin}} \; E_\text{d2m} + E_\text{m2d} + E_\text{rigid} + E_\text{valid}
% \end{equation*}
% \subsection{Optimization}

% The first attempt was to make the model-data energy also the same as in Htrack. But probably due to more non-linear gradients that expression was giving unstable optimization, because it was involving a projection operator. So, the model-data energy is replaced by a similar energy, but in 3D space. \Anastasia{Maybe we could just say that it is exactly the same?}.
% The model-data correspondences are also computed by rendering the model and the data, identifying the model points that are outside of the data silhouette and finding the closest data points in 2D using a distance transform. Afterwards for each 2D correspondence pair $\{m_{2D}, p_{2D}$\}, the original 3D points $\{m, p\}$ are looked up. We minimize the distance between $m$ and $p$ in the direction orthogonal to the camera ray that goes through $p$.
% \input{fig/optimization/item}
% \begin{equation*}
% E_\text{model-data} = \underset{m\in M}\sum n^T(p - m(\sigma))
% \end{equation*}