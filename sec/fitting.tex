% !TEX root = ../hmodel.tex

\section{Modeling}
\label{sec:modeling}
% 
%In this section explain how we build our template model in an off-line preprocess and then discuss how this template can be adjusted to a specific user from RGBD sensor data. \AT{this makes it sounds like a two-steps approach... but it's really not? Also see below.}
%
%\subsection{Template construction}
%\begin{DRAFT}
%To obtain an accurate representation of hand geometry in different articulations, we scan a hand by taking on the order of ?? high-resolution photographs from different viewpoints for ?? different poses. From these images we compute dense point clouds for each pose using \emph{Agisoft Photoscan~\textcopyright}.
%We manually specified the topology of our convolution surface depicted in Figure~\ref{fig:topology}. Then we optimize for the positions and radii, using manually specified initial values.
%\end{DRAFT}
%\AT{I am very confused about this ``template construction'' phase. As you can see in \Figure{calibration} there is not much to construct!}
%
%
%
%\subsection{User calibration} 

\brief{Multi-Pose Data}
Our calibration procedure tailors our template model to a specific user from a set of $N$ 3D measurements $\{ \depth_1 \dots \depth_N \}$ of the user's hand in different poses. Multiple measurements are necessary as it is not possible to understand the kinematic behavior by analyzing static geometry, while the redundancy of information improves fitting precision. Further, in monocular monocular acquisition this is essential, as single-view data is highly incomplete making the problem ill-posed. In our research we have experimented with datasets $\{\depth_i\}$ acquired via from multi-view stereo (e.g.\ \emph{Agisoft Photoscan~\textcopyright}), as well as single RGBD sensor. Our calibration formulation can be employed for both acquisition modalities.

\input{fig/posing/item.tex}
\brief{Posing the model}
The rest-pose geometry of a convolution model is fully specified by two matrices specifying the set of sphere positions $\centers$ and radii $\radii$. The geometry is then posed through the application of  kinematic chain transformations; see \Figure{posing}. Given a point $\bar\point$ on the model $\model$ at rest pose, its 3D position after the model has been posed can be computed by evaluating the expression:
% 
\begin{equation}
\point = \left[ \Pi_{k \in K(i)} \mathbf{\bar{T}}_k \mathbf{T}_k \mathbf{\bar{T}}_k^{-1} \right] \bar\point
\label{eq:kinematic}
\end{equation}
%
where each node of the kinematic chain is associated with an orthogonal frame $\mathbf{\bar{T}}_k$ according to which local transformations are specified. 
% However, this is not sufficient, as most tracking systems, including the one we build upon, parameterize a pose through the specification of a kinematic chain.
% An an example, transformations for the index finger are parameterized so to result in \todo{flexion} (resp. \todo{abduction}) as a rotation around the local $x$ (resp. $y$) axis.
In most tracking systems frame origin and axes are manually specified by a 3D modeling artist. Identifying the correct 


While for most articulations such an approximation is somewhat acceptable, it is particularly challenging to select the correct reference frame for the thumb articulation. In the accompanying video \todo{[00:00]}, we show how incorrect initialization of $\mathbf{\bar{T}}$ can be highly detrimental to tracking quality. For this reason, in our formulation the kinematic structure is automatically inferred from acquired data.

\begin{DRAFT}
\paragraph{Posing the model}
\label{sec:posing}
% 
To pose a convolution model the centers ... 
Where $\Pi$ left multiplies matrices by traversing the kinematic chain $K(i)$ of element $i$ towards the root.
... $\bar\ballcenter_i$ are written in world coordinates.
% 
% 
Basically we express the point int he coordinate frame of the k-th element, we apply the posing transformation, then we re-apply the rest pose transformation to bring the point back in world coordinates. ... \TODO{mention \Figure{posing}}
\end{DRAFT}

\paragraph{Formulation}
Let us partition our free parameters into two sets $\parposture$ and $\parpose$. 
The vector $\parpose_n$ contains the pose parameters optimally aligning the rest-pose template to the data frame $\depth_n$, (i.e. pose). 
The vector $\parposture$ contains the Euler angles parameterizing the rest-pose transformations $\mathbf{\bar{T}}$ in \Eq{kinematic} (i.e. posture).
% 
\AT{We should write $\restcenters$ as the positions at rest, while $\posedcenters$ as the set of posed convolution models. This would make the formulation cleaner.} Our calibration optimization can then be written as:
% 
\begin{eqnarray}
\argmin_{\parposture, \centers, \radii}
\sum_{n=1}^N 
\sum_{\mathcal{T} \in \termscalib} 
w_\mathcal{T} E_\mathcal{T}(\depth_n, \parpose_n, \parposture, \centers, \radii)
\label{eq:calibration}
\end{eqnarray}
% 
We employ a set of energies $\termscalib$ to balance different desired traits. On one side we would like our model $\model$ to be a good fit to our data, on the other we require each posed model to be a piecewise-rigid posing of a non-degenerate convolution template. Our energies $\termscalib$ are:
% 
\begin{description}[labelsep=0em,labelwidth=.4in,labelindent=1cm]
\item[d2m] each data point is explained by the model
\item[m2d] the model lies in the sensor visual-hull
% \item[d2m] the data should lie close to our model
% \item[m2d] the model should lie close to the data
\item[rigid] convolution elements are posed rigidly
\item[valid] convolution elements should not degenerate
\end{description}
% 
To make this calibration more approachable numerically, we rewrite \Eq{calibration} as an iterative alternating optimization problem:
% 
\begin{eqnarray}
\tilde\centers = 
\argmin_{\parposes,\parposture,\centers} 
\sum_{n=1}^N 
\sum_{\mathcal{T} \in \termscalib}
w_\mathcal{T} E_\mathcal{T}(\parpose_n, \parposture, \centers) 
& \text{(Step 1)}
\label{eq:step1}
\\
\left[ \centers, \radii \right] =
\argmin_{\centers, \radii} 
\sum_{n=1}^N 
\sum_{\mathcal{T} \in \termscalib}
w_\mathcal{T} E_\mathcal{T}(\depth_n, \tilde\centers, \radii)
& \text{(Step 2)}
\label{eq:step2}
\end{eqnarray}
% 
In the first step, pose and posture are optimized jointly by fixing the geometry of the template and aligning multiple instances to each frame. The kinematic chain is adjusted by refining the rest-pose transformations $\mathbf{\bar{T}}_k$; note only the rotational degrees of freedom of $\mathbf{\bar{T}}_k$ are optimized for, as frame translations are inferred from $\skeleton$. 
\todo{This optimization projects the posed centers $\posedcenters$ onto the closest point on the manifold of convolution surfaces respecting the given kinematic constraints.}
% 
In the second step, sphere centers and radii of our convolution model are adjusted, thus altering the rest pose geometry $\restcenters$ of the convolution model to better conform to the user.

\paragraph{Optimization and Initialization}
The energies above are non-linear and non-convex, but can be optimized offline, as in real-time tracking we can use a pre-calibrated model. For this reason, we can use the convenient $lsqnonlin$ routine from Matlab, requiring us to specify the energies gradients (see \Appendix{gradients}) as well as an initialization point. The initialization of $\centers$ is performed by simply scaling the vertices of a generic template to roughly fit the rest pose. The initial transformation frame rotations $\parposture$ are retrieved from the default template, while $\parposes$ are obtained by either aligning the rough template to the input data (for depth images) or by executing IK registration of a few manually selected key-points (for MVS reconstructed models).

\input{fig/calibration/item.tex}

\subsection{Energies}
We now describe in detail the various energies of our optimization. For notational brevity, we gather the parameters of our model as $\pars_n=[\parpose_n, \parposture, \centers, \radii]$.

\TODO{RE-WRITE THE FITTING ENERGIES?}
\begin{DRAFT}
\begin{equation}
E_{\model \rightarrow \depth} = \sum_{\point \in \model(\pars_n)} \| \point - \proj_{\depth_n}(\point)\|_2^1
\label{eq:m2d}
\end{equation}
As we are seeking for a model which is strictly sufficient to represent our data, we need to ensure that \todo{no portion of the model remains unused} \AT{better way of saying this?}. 
The data-to-model term encodes an approximation of the \emph{one-sided} Hausdorff distance, but this is insufficient in applications where the tracking template is unknown. An approximation of the \emph{symmetric} Hausdorff distance can be obtained by also accounting for model-to-data correspondences
% 
Note that the projection operator $\proj_{\depth_n}$ changes according to the type of input data being used. If a multi-view acquisition system is used to acquire a complete point cloud, then the projection operator is similar to the one used for \Eq{d2m}: we build a kd-tree for the point cloud in frame $\depth_n$ and fetch the closest point to $\point$. Conversely, if the data in $\depth_n$ has been obtained through monocular acquisition, then $\proj_{\depth_n}$ computes the 2D projection to the image-space silhouette of the model.
\end{DRAFT}

\paragraph{Rigidity}
It is essential that we recover a template that \emph{jointly} fits the set of data frames $\{ \depth_n \}$. We achieve this task by requiring each posed model to be a piecewise-rigid articulation of our rest pose. This can be achieved by simply requiring that each segment $\edge$ in our posed control skeleton $\skeleton_n$ to have the same length as the corresponding segment $\bar\edge$ in the rest pose configuration:
% 
\begin{equation}
E_{\text{rigid}} = \sum_{\edge \in \skeleton_n} (\| \edge \| - \| \bar\edge \|)^2
\end{equation}
% 
Note that only a subset of the edges of our control skeleton, as illustrated in \Figure{topology}, are required to satisfy the rigidity condition.

\paragraph{Validity}
It is essential to prevent the calibration optimization from producing degenerate configurations. For example, a pill degenerates into a sphere when one of its balls is fully contained within the the volume of other. Analogously a wedge can degenerate into a pill, or even a sphere. We monitor validity by an indicator function $\chi(\ball_i)$ evaluating to one if $\ball_i$ is degenerate and zero otherwise.
Degeneracies can be avoided by including the energy term:
% 
\begin{equation}
E_{\text{valid}} = \sum_{\ballcenter_k \in \skeleton} \chi(\ballcenter_k) \| \ballcenter_k - \proj_{\model \setminus \ball_k}(\ballcenter_k) \|_2^2
\end{equation}
% 
In this equation, we make a conservative choice and use $\chi(\ballcenter_i)$, which verifies whether $\ballcenter_i$ is inside $\model \setminus \ball_i$, the model obtaining by removing a vertex, as well as all its adjacent edges, from $\skeleton$. 

\endinput

\paragraph{Rigidity - OLD}
\begin{DRAFT}
We encode this requirement by requiring each edge $\edge_k$ in each posed skeleton $\skeleton_n$ to be a rotation of rotation $R_{k}$ of its rest-pose configuration~$\bar\edge_k$: 
\begin{equation}
E_{\text{rigid}} = \sum_{\edge_k \in \skeleton_n} \| \edge_k  - R_{k}{\bar\edge_k} \|_2^2
\label{eq:rigidity}
\end{equation} 
Note that only a subset of the edges of our control skeleton, as illustrated in \Figure{topology}, are required to satisfy this rigidity requirement. At the cost of introducing auxiliary variables $R_{i}$, this energy becomes independent from pose $\parposes$ and posture $\parposture$ angles.
\end{DRAFT}


% The first reason is that we want ensure that the resulting hand model will be able to assume all the poses that a real hand can, or at least the subset of poses for which we have the point clouds.
% The second reason is that the artifacts present in some input point clouds might be compensated by the others, so it is possible to accumulate information this way.
% For fitting we use the same optimization framework as for tracking (in a hope to extend it to fitting \& tracking real time system).
% The main difference is that instead of the joint angles $\theta$, the hand model is parametrized by convolution surface centers locations and radii $[c , r]$.
% \begin{equation*}
% \sigma =\underset{\sigma}{\operatorname{argmin}} \; E_\text{d2m} + E_\text{m2d} + E_\text{rigid} + E_\text{valid}
% \end{equation*}
% \subsection{Optimization}

% \paragraph{Synchronizing rotations energy}
% \AT{This is now obsolete, as we encode common rotation frames for nodes of the kinematic chain} This energy ensures that initial rotations are similar for all the poses. The common initial rotations are computed as described in the section ``Initial Rotations''. The energy minimizes the distance between the current centers and the centers locations with common initial rotations. This energy is very important, because it constraints fingers motion in meaningful way. In the absence of this energy each joint bends in arbitrary direction.

% The first attempt was to make the model-data energy also the same as in Htrack. But probably due to more non-linear gradients that expression was giving unstable optimization, because it was involving a projection operator. So, the model-data energy is replaced by a similar energy, but in 3D space. \Anastasia{Maybe we could just say that it is exactly the same?}.
% The model-data correspondences are also computed by rendering the model and the data, identifying the model points that are outside of the data silhouette and finding the closest data points in 2D using a distance transform. Afterwards for each 2D correspondence pair $\{m_{2D}, p_{2D}$\}, the original 3D points $\{m, p\}$ are looked up. We minimize the distance between $m$ and $p$ in the direction orthogonal to the camera ray that goes through $p$.
% \input{fig/optimization/item}
% \begin{equation*}
% E_\text{model-data} = \underset{m\in M}\sum n^T(p - m(\sigma))
% \end{equation*}

% This energy ensures that pills do not degenerate into spheres and wedges do not degenerate into pills. A pill becomes degenerate if one of the spheres is completely inside of another sphere. A wedge becomes degenerate if a sphere is completely inside of the tangent cone of two other spheres. The energy switches on if a pill or a wedge is within a threshold of becoming degenerate and pushes the optimization away.