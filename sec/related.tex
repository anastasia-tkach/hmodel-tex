% !TEX root = ../hmodel.tex

% USE THIS? (good hand model key to high-quality in-hand scanning)
% http://files.is.tue.mpg.de/dtzionas/In-Hand-Scanning/

% I IGNORED THIS ONE, NOT ENOUGH DETAILS:
% Straka et al. \cite{straka2012simultaneous} also fit the template mesh with attached skeleton to 3D data. The model is deformed to explain the data while keeping the vertices attached to their corresponding bones. It is on clear whether the approach whether be able to handle a hand motion sequence, since the results are demonstrated on a full body model.

\input{fig/handmodels/item.tex}
\section{Related Work}
\label{sec:related}

% \paragraph{Overkill} %< Instrumented + Multi-Camera
The simplest way of tracking a hand in motion is by instrumentation. We can place retro-reflective markers on the hand~\cite{zhao2012marker}, wear a data glove with embedded abduction and flexion sensors~\cite{dipietro2008survey} or a colored glove~\cite{wang2009colorglove}. While effective, active instrumentation can be cumbersome as it requires lengthy preparation and/or calibration. 
%\AnastasiaComment{We do we talk about these systems, they are from a different area and are solving completely different problems. If someone wrote related literature this way before, it does not mean that we have to do the same.}
Systems solely relying on computer vision (i.e.\ color cameras) are highly desirable, but pose estimation  relying on color information is extremely challenging~\cite{erol2007survey}: the complexity of hand motion, the large number of self-occlusions and rapidly changing backgrounds all contribute to its limited success so far. Multiple-camera acquisition can mitigate these challenges. In \cite{ballan2013salient}, the authors demonstrate high-quality tracking of two-hand and hand-object interactions, while \cite{wang2013physics} additionally considers the physics of motion interaction. However, due to the substantial increase in data bandwidth, these algorithms do not scale to real-time performance (a notable exception is the 10Hz system of  \cite{sridhar2013multicam}, but this acquisition setup also considers data from a depth sensor). While providing accurate results, multi-camera rigs are  impractical for consumer-level applications. Therefore, we limit our attention to techniques relying on data from a \emph{single} depth camera; with a slight abuse of wording we refer to it as a \emph{monocular} acquisition setup.
% IGNORED THIS: place a camera directly on the user's wrist~\cite{kim2012digits}.

\paragraph{Hybrid = discriminative + generative}
% 
Pose estimation techniques can be grouped into \emph{discriminative} and \emph{generative} techniques, also known respectively as \emph{appearance-based} and \emph{model-based} approaches.
% Generative
Generative approaches fit a template through a temporal sequence of images~\cite{oiko2011hand,melax2013dynamics,schroder2014real,tagliasacchi2015robust}. Given an accurate template of the user being tracked, these methods can resolve highly accurate motion. As the optimization is initialized from the previous frame, tracking loss can occur, although simple geometric reinitialization heuristics can be employed to overcome this issue~\cite{melax2013dynamics,qian2014realtime}. 
% Discriminative
Conversely, discriminative methods estimate the pose by extracting features from each image independently by learning from a large dataset of annotated exemplars~\cite{keskin2012hand,tang2013real,tejani2014latent,sun2015cascaded}.
While discriminative methods avoid drift, they lack the accuracy of generative methods, and joint estimates often violate kinematic constraints, like consistent finger lengths and joint limits.
% Hybrid-1
The state-of-the-art in tracking performance is achieved by \emph{hybrid} algorithms that combine the two approaches. These algorithms estimate (potentially) multiple per-frame coarse poses leveraging discriminative frameworks, and then refine the alignment with a generative fitting~\cite{tompson2014real,qian2014realtime,sharp2015accurate}.
% Hybrid-2
Another class of hybrid algorithms introduce correspondences through a labeling obtained through a per-pixel forest  classifier~\cite{sridhar2015fast,fleishman2015icpik}.
% 
% What we (do not) cover?
Our literature review focuses on generative approaches, while we refer the reader to the very recent work by Taylor and colleagues \shortcite{taylor2016concerto} for a review of recent discriminative methods. Commercial systems for hand tracking like the \emph{NimbleVR\textcopyright}, the \emph{LeapMotion Orion\textcopyright} and the \emph{Intel Perceptual SDK\textcopyright} also exist, but it is difficult to consider them as the underlying technology is currently undisclosed. 
% \AT{I tested them and I \emph{think} they are discriminative}

\paragraph{Generative tracking models}
The capsule model originally proposed by~\cite{rehg1994tracking} has been adopted by a number of researchers \cite{oiko2011hand,schroder2014real,fleishman2015icpik,tagliasacchi2015robust}; see \Figure{handmodels}(a). Such a coarse representation is suitable to the task given the low signal-to-noise ratio in modern depth sensors, while its simplicity enables the efficient closed-form computation of alignment queries. Cylinders can also be approximated by a small set of disconnected spheres~\cite{qian2014realtime}, but this rough approximation is only sufficient for coarse-scale tracking; see \Figure{handmodels}(b). An alternative to cylinders and spheres is the use of isotropic~\cite{sridhar2013multicam,sridhar2015fast}, as well as anisotropic Gaussians~\cite{sridhar2014anisotropic}; while registration gradients can conveniently be computed in closed-form, the resulting tracking model is not appropriate for high-precision tracking.
% 
% \todo{Our research pioneers the generalization of these tracking templates into convolution surfaces, and by doing so it demonstrates a substantial increase in real-time tracking precision.}
%
The use of surface meshes, while widespread in other domains (e.g.\ face tracking~\cite{bouaziz2013online} or offline registration~\cite{wang2013physics,loper_eccv14}), has been limited to the visualization of tracking performance through skinned model animations~\cite{tompson2014real,schroder2014real}. Sharp et al.~\shortcite{sharp2015accurate} employed mesh models for tracking in a render-and-compare framework, while the very recent work of~\cite{taylor2016concerto} presents the very first attempt towards continuous registration framework for meshes; see~\Figure{handmodels}(c).
%
Other variants of tracking models include the union of convex bodies from~\cite{melax2013dynamics}, a convolutional neural network capable of synthesizing depth images of a posed model~\cite{oberweger2015feedback}, and even some rough attempts at tracking with implicit models~\cite{fua2003soft}.
% 
The convolution model we propose offers accuracy comparable to triangle meshes used in modern real-time trackers, while retaining a compact representation for efficient correspondence queries and effective user adaptation.
% \AnastasiaComment{Can you please also mention its dynamic properties that I mention in the video: that it can do rigid articulation like a cylinder model, and at the same time can represent skin elasticity, like a triangular mesh? MP: Not sure how to write this. People can argue that you can do the same for triangle meshes, you just need to label the deformation properties of each triangle, which can be done once on the template.}

\input{fig/zsphere/item.tex}
\paragraph{Template calibration}
Albrecht et al.~\shortcite{albrecht2003construction} pioneered the creation of a realistic hand model (i.e. bones and muscles) by aligning a template mesh to data acquired by a laser-scanned plaster cast. Rhee et al.~\shortcite{rhee2006hand} use a simpler setup consisting of a single color image to identify approximate joint locations by localizing skin creases, and adapt a mesh template to conform to its silhouette. While these methods focus on a static template, in \cite{delagorce2011model} a model is roughly adapted to the user (\todo{through simple bone scaling}) to produce the first \emph{animatable} template. 
% 
\todo{Calibration of a cylinder model through particle swarm has been investigated in~\cite{makris2015adapt}.
% 
More advanced calibration was further addressed by~\cite{taylor2014user}, where the model is adjusted to \emph{jointly} fit a set of depth frames. This method was extended in~\cite{khamis15learning}, where the authors pioneered compact and linear shape-spaces of human hand geometry.}
% 
The method in \cite{taylor2014user} shares some similarities with our work, but with a fundamental difference in the way in which geometry is represented. Our convolutional model is \emph{naturally compact}, leading to straightforward calibration and tracking algorithms.

\paragraph{Implicit modeling}
Implicit sculpting tools have recently become a viable alternative to mesh or spline-based approaches for modeling complex geometries. This paradigm lies at the basis of the success of the \emph{PixoLogic ZBrush\textcopyright} product line. 
For articulated geometry, it is often convenient to first create a coarse geometric structure analogous to the one described in~\Equation{convsurf}, a process that \emph{PixoLogic} has re-branded as \emph{ZSphere{\textcopyright}} modeling; see \Figure{zsphere}. Editing the radii and centers of the convolution model offers a \emph{natural} way of editing the model, making it easy for both humans and algorithms to calibrate.
% Manually calibrating a convolution model is intuitive for a human, as it involves editing of a few sphere centers and radii. This leads to a simple and effective automated calibration algorithm.
Note that any geometric model can be approximated, to any desired precision, as a union of spheres~\cite{tagliasacchi2016skeletons}. 
However, by considering spheres that are linearly interpolated across edges, we can heavily reduce the required number of primitives. Following this principle, \cite{thiery2013sphere} recently investigated a method to automatically generate \emph{Sphere Meshes} provided a  (static) input model. Extending this work, \cite{thiery2016spheremesh} proposed a method to fit a model to a sequence of dynamic meshes. While seemingly related, our calibration optimization is solving a fundamentally different problem, because in our technique a template is provided in input. However, a mixture of implicit and explicit representations is key in achieving high quality skinning deformations at interactive rates \cite{vaillant2013implicit,vaillant2014robust}.

%----------------------------------------------------------------------
%----------------------------------------------------------------------
%----------------------------------------------------------------------
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\endinput

% Taylor et. al.  generate a user-specific hand model from an RGBD video sequence. The model is represented as a triangular mesh with an embedded skeleton. In each frame the hand pose is initialized using an appearance-based tracking algorithm. The hand model parameters are found by solving a single optimization problem formulated for the entire video sequence which also finds hand pose in each frame.

% Khamis et. al.   fit a hand model for a specific user by finding its shape coordinates in the basis of mesh matrices and bones locations. As in the approach by Taylor et. al, they optimize simultaneously for pose and shape parameters in all the frames of an RGBD sequence across all the subjects. Requires large number of subjects as a regularization for excessive degrees of freedom.

%--- LINEAR BLEND SKINNING
% \TODO{The Linear Blend Skinning approach used to pose the triangular mesh model in previous works (\cite{sharp2015accurate}, \cite{schroder2013analysis} ) creates artifacts, the fingers looks like made from rubber. The spheres/cylinders model is not suitable for realistic animation, therefore a re-targeting step to a template mesh is required. Retargeting does not only demand additional effort, but also brings additional imprecision. }

%--- CLOSEST POINT COMPUTATIONS
% \TODO{For model based tracking the main operation is to find the closest point on the model for a given data point. This operation is can be done in closed for each rigid segment with spheres/cylinder and convolution surfaces model representation. For a triangular mesh this operation has complexity linear in number of triangles. Thus, it is necessary to simplifying assumptions and/or more complex optimization to allow the hand tracking system to run in real time. (Look how different systems deal with this problem). Moreover, the triangular mesh has (much) more degrees of freedom than the underlying problem. Without additional regularization, rigid parts of the hand model can deform to fit the data and the individual vertices can shift to fit the sensor noise.}
