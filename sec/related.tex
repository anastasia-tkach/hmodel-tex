% !TEX root = ../hmodel.tex

% USE THIS? (good hand model key to high-quality in-hand scanning)
% http://files.is.tue.mpg.de/dtzionas/In-Hand-Scanning/

% I IGNORED THIS ONE, NOT ENOUGH DETAILS:
% Straka et al. \cite{straka2012simultaneous} also fit the template mesh with attached skeleton to 3D data. The model is deformed to explain the data while keeping the vertices attached to their corresponding bones. It is on clear whether the approach whether be able to handle a hand motion sequence, since the results are demonstrated on a full body model.

\input{fig/handmodels/item.tex}
\section{Related Work}
\label{sec:related}
% \AT{we cover tracking and convsurf, should we have a sentence or two stating that?}

% \paragraph{Overkill} %< Instrumented + Multi-Camera
The simplest way of tracking a hand in motion is by instrumentation. We can place retro-reflective markers on the hand~\cite{zhao2012marker}, wear a data glove with embedded abduction and flexion sensors~\cite{dipietro2008survey} or a colored glove~\cite{wang2009colorglove}. While effective, active instrumentation can be cumbersome as it requires lengthy preparation and/or calibration. Systems solely relying on computer vision (i.e. color cameras) are highly desirable, but pose estimation  relying on color information is extremely challenging~\cite{erol2007survey}: the complexity of hand motion, the large number of self-occlusions and rapidly changing backgrounds all contribute to its limited success. Multiple-camera acquisition can mitigate these challenges. In \cite{ballan2013salient}, the authors demonstrate high-quality tracking of two-hand and hand-object interactions, while \cite{wang2013physics} additionally considers the physics of motion interaction. However, due to the substantial increase in data bandwidth, these algorithms do not scale to real-time performance (a notable exception is the 10Hz system of  \cite{sridhar2013multicam}, but this acquisition setup also considers data from a depth sensor). While providing accurate results, multi-camera rigs are completely impractical for consumer-level applications. Therefore, we limit our attention to techniques relying on data from a \emph{single} depth camera; with a slight abuse of wording we refer to it as a \emph{monocular} acquisition setup.
% IGNORED THIS: place a camera directly on the user's wrist~\cite{kim2012digits}.

\paragraph{Hybrid = discriminative + generative \todo{SKIP or CONDENSE?}}
Pose estimation techniques can be grouped into \emph{discriminative} (i.e.\ appearance-based) and \emph{generative} (i.e.\ model-based) approaches. 
% Generative
Generative approaches fit a template through a temporal sequence of images~\cite{oiko2011hand,melax2013dynamics,schroder2014real,tagliasacchi2015robust}. Given an accurate template of the user being tracked, these methods can resolve highly accurate motion. However, as the alignment optimization is initialized from the previous frame tracking loss can occur. \AT{mention re-init heuristics?}
% Discriminative
Conversely, discriminative methods estimate the pose by extracting features from each image independently by learning from a large dataset of annotated exemplars~\cite{keskin2012hand,tang2013real,tejani2014latent,sun2015cascaded}. While discriminative methods are robust to tracking drift, they lack the accuracy of generative methods. \AT{also the joint estimates might violate kinematic constraints?}
% Hybrid
The state-of-the-art in tracking performance is achieved by \emph{hybrid} algorithms that combine the two approches. These hybrid algorithms estimate (potentially) multiple per-frame coarse poses leveraging discriminative frameworks, and then refine the alignment with a generative fitting~\cite{tompson2014real,qian2014realtime,sharp2015accurate,sridhar2015fast}. 
\AT{was Sridhar doing this? or was he just using pixel-classification?}.
% What we (do not) cover?
Our literature review focuses on generative approaches, while we refer the reader to the very recent work by Taylor and colleagues \shortcite{taylor2016concerto} for a review of recent discriminative methods. Commercial systems for hand tracking like the \emph{NimbleVR\textcopyright}, the \emph{LeapMotion\textcopyright} and the \emph{Intel Perceptual SDK\textcopyright} also exist, but it is difficult to consider them as the underlying technology is undisclosed. 
\AT{I tested them and I \emph{think} they are discriminative}

\paragraph{Generative tracking models}
The capsule model originally proposed by~\cite{rehg1994tracking} has been adopted by a number of researchers \cite{oiko2011hand,schroder2014real,fleishman2015icpik,tagliasacchi2015robust}; see \Figure{handmodels}(a). Such a coarse representation is suitable to the task given the low signal-to-noise ratio in modern depth sensors, while its simplicity enables the efficient closed-form computation of alignment queries. Cylinders can also be approximated by a small set of disconnected spheres~\cite{qian2014realtime}, but this rough approximation is only sufficient for coarse-scale tracking; see \Figure{handmodels}(b). An alternative to the use of cylinders and spheres is the use of isotropic~\cite{sridhar2013multicam,sridhar2015fast}, as well as anisotropic~\cite{sridhar2014anisotropic}, gaussians; while registration gradients can conveniently be computed in closed-form, the resulting tracking model is not appropriate for high-precision tracking.
% 
% \todo{Our research pioneers the generalization of these tracking templates into convolution surfaces, and by doing so it demonstrates a substantial increase in real-time tracking precision.}
%
The use of surface meshes, while widespread in other domains (e.g. face tracking~\cite{bouaziz2013online} or offline registration~\cite{wang2013physics,loper_eccv14}), has been limited to the visualization of tracking performance through skinned model animations~\cite{tompson2014real,schroder2014real}. Sharp et al.~\shortcite{sharp2015accurate} employed mesh models for tracking in a render-and-compare framework, while the very recent work of~\cite{taylor2016concerto} presents the very first attempt towards continuous registration framework for meshes; see~\Figure{handmodels}(c).
%
Other variants of tracking models include the union of convex bodies from~\cite{melax2013dynamics}, or the use of geometry synthetically generated from a neural network~\cite{oberweger2015feedback}~\TODO{check}.

\paragraph{Template calibration}
Albrecht et al~\shortcite{albrecht2003construction} pioneered the creation of a realistic hand model (i.e. bones and muscles) by aligning a template mesh to data acquired by a laser-scanned plaster cast. Leveraging a simpler setup consisting of a single color image, \cite{rhee2006hand} identified approximate joint locations by localizing skin creases, and adapted a mesh template to conform to its silhouette. While these methods focused on a static template, in \cite{delagorce2011model} a model is roughly adapted to the user (\todo{through simple bone scaling}) to produce the first \emph{animatable} template. More advanced calibration was further investigated by~\cite{taylor2014user}, where the model is adjusted to \emph{jointly} fit a set of depth frames. This method was extended in~\cite{khamis15learning}, where the authors pioneered compact \AT{compact == low DOF} \todo{?linear?} shape-spaces of human hand geometry.
% 
The method in \cite{taylor2014user} shares a few similarities with our work, but with a fundamental difference in the way in which geometry is represented. Our convolutional model is \emph{naturally compact}, leading to straightforward calibration and tracking algorithms. \TODO{missing the calibration work from forth?}

\input{fig/zsphere/item.tex}
\paragraph{Convolution Modeling}
In contrast to explicit polygonal modeling, sculpting implicit surfaces provides a more natural way of designing complex geometry, and this process lies at the basis of the enormous success of the \emph{PixoLogic ZBrush~\textcopyright} product line. 
For articulated geometry, it is also convenient to first create a coarse geometric structure analogous to the one described in~\Equation{convsurf}, a process that \emph{PixoLogic} has re-branded as \emph{ZSphere~{\textcopyright}} modeling; see \Figure{zsphere}. Manually calibrating a convolution model is intuitive for a human, as it involves editing of a few sphere centers and radii. This leads to a simple and effective automated calibration algorithm. Note that any geometric model can be approximated, to any desired precision, as a union of spheres~\cite{tagliasacchi2016skeletons}. 
However, by considering spheres that are linearly interpolated across edges, we can heavily reduce the required number of primitives. Following this principle, \cite{thiery2013sphere} recently investigated a method to automatically generate \emph{Sphere Meshes} provided a  (static) model in input. Extending this work, \cite{thiery2016spheremesh} proposed a method to fit a model through an (dynamic) animated mesh. While seemingly related, our calibration optimization is solving a fundamentally different problem, as in our technique a template is provided in input. 
Tracking with an implicit model has also received little attention in the literature, with \cite{fua2003soft} being a notable exception. However, a mixture of implicit and explicit representations is key in achieving high quality skinning deformations at interactive rates \cite{vaillant2013implicit,vaillant2014robust}.

%----------------------------------------------------------------------
%----------------------------------------------------------------------
%----------------------------------------------------------------------
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\endinput

% Taylor et. al.  generate a user-specific hand model from an RGBD video sequence. The model is represented as a triangular mesh with an embedded skeleton. In each frame the hand pose is initialized using an appearance-based tracking algorithm. The hand model parameters are found by solving a single optimization problem formulated for the entire video sequence which also finds hand pose in each frame.

% Khamis et. al.   fit a hand model for a specific user by finding its shape coordinates in the basis of mesh matrices and bones locations. As in the approach by Taylor et. al, they optimize simultaneously for pose and shape parameters in all the frames of an RGBD sequence across all the subjects. Requires large number of subjects as a regularization for excessive degrees of freedom.

%--- LINEAR BLEND SKINNING
% \TODO{The Linear Blend Skinning approach used to pose the triangular mesh model in previous works (\cite{sharp2015accurate}, \cite{schroder2013analysis} ) creates artifacts, the fingers looks like made from rubber. The spheres/cylinders model is not suitable for realistic animation, therefore a re-targeting step to a template mesh is required. Retargeting does not only demand additional effort, but also brings additional imprecision. }

%--- CLOSEST POINT COMPUTATIONS
% \TODO{For model based tracking the main operation is to find the closest point on the model for a given data point. This operation is can be done in closed for each rigid segment with spheres/cylinder and convolution surfaces model representation. For a triangular mesh this operation has complexity linear in number of triangles. Thus, it is necessary to simplifying assumptions and/or more complex optimization to allow the hand tracking system to run in real time. (Look how different systems deal with this problem). Moreover, the triangular mesh has (much) more degrees of freedom than the underlying problem. Without additional regularization, rigid parts of the hand model can deform to fit the data and the individual vertices can shift to fit the sensor noise.}
