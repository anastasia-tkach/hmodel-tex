% !TEX root = ../hmodel.tex
% Problem Statement: What's the problem you want to solve?
% 
% Motivation: Why is this an interesting problem? Who cares about it? Why now? Why is it appropriate for the conference audience?
% 
% Research Gap, Novelty: Why is new research required? Why can the problem not be solved with existing methods? How does the proposed solution differ from and/or improve upon existing work?
% 
% Technical Contribution: What's the key technical idea to solve the problem? Why is it beautiful?
% 
% Applications / Future Work: What will your solution enable? How does it project into the future? How will it inspire future work?



% NOTE: the paragraph names can be removed later on
\section{Introduction}
With the imminent advent of consumer-level virtual and augmented reality technology, the ability to interact with the digital world with the most natural means of interaction, our hands, becomes of paramount importance. Most importantly, the degree of immersion in the virtual world is directly correlated to whether the user perceives his own realistic hands~\todo{\cite{immersion}}. Over the past two decades the research community has explored a number of techniques to address this problem, from expensive and unwieldy marker-based mocap~\todo{\cite{mocapsurvey}} to instrumented gloves~\cite{dipietro2008survey} as well as imaging systems~\cite{erol2007survey}. Multi-camera imaging systems can recover the hand pose and hand-objects interactions with high accuracy~\cite{ballan2013salient}, but the only system capable to approach interactive applications is the ~10 fps system of~\cite{sridhar2013multicam}. Conversely, in this paper we focus on hand motion tracking with a single RGBD sensor (e.g.\ Intel RealSense or Microsoft Kinect), as commonly predicted to be readily available in a typical AR/VR consumer experience.

\paragraph{Tracking: discriminative v.s. generative}
Modern systems for real-time tracking from RGBD data  \cite{sridhar2015fast,sharp2015accurate} rely on a combination of \emph{discriminative} approaches like \cite{keskin2012hand}, and \emph{generative} approaches such as \cite{oiko2011hand}. The per-frame re-initialization of discriminative methods prevents error propagation by offering a continuous recovery from tracking failure. As these discriminative models are learned from data, they typically only estimate a coarse pose. Therefore, generative models are used to refine the estimate by aligning a geometric template of the user hand to the measured point cloud and to regularize its motion through time. It is not surprising that the quality of the template directly affects the quality of pose refinement; see \Figure{teaser}. 
\TODO{mention no need to re-init $\gg$FPS?}.

The main goal of this paper is to explore novel tracking models that strike an optimal balance between accuracy and performance. More specifically, we propose a geometric model that more accurately captures the user's hand geometry, while retaining the ability to answer registration queries in closed form with very high efficiency. In \Figure{coarsemodel} and \todo{Video [00:00]} we illustrate the importance of employing a tracking template that strikes this delicate balance.

% \paragraph{Model calibration.}
% As generative models perform tracking by fitting a geometric model to what is measured by the sensor, our template should be able to represent well the observed data. However, even in modern trackers, the discrepancy between the optimal model pose given the data and the true hand pose can be significant. For example, the sources of discrepancy in \Figure{coarsemodel} include the incorrect length of fingers and the lack of the \todo{[pinky-ring]} degree of freedom. \todo{In the literature, the creation of user-specific models for tracking is referred to as \emph{calibration}.}

\input{fig/coarsemodel/item.tex}
\paragraph{Implicit v.s. explicit templates}
In modern digital production representing objects by a surface mesh of their boundary (e.g.\ triangle or quad meshes) is the de-facto standard. Fast rendering and easy direct manipulation make \emph{explicit} surface representation attractive for many applications.
%
However, unlike \emph{implicit} models~\cite{bloomenthal1997book}, explicit representations cannot efficiently answer queries such as the distance from a point to the object's boundary, or whether a point lies inside/outside the model~\cite[Ch.1]{botsch2010book}. In tracking applications these queries play a fundamental role, as the optimization attempts to find configurations where the average \emph{distance} from model to data is minimized. Similarly, a tracker should prevent the model from assuming implausible configurations, for example by preventing self-intersections as measured by inside/outside predicates. For all these reasons, implicit models appear optimal for registration applications; indeed, compelling results in joint rigid registration and reconstruction~\cite{newcombe2011kinfu} as well as its recent non-rigid variant~\cite{newcombe2015dynfusion} leverage implicit models. One important observation is that such techniques assume the frame-rate is high compared to motion velocity, a condition that is in general not satisfied in our setting.  To address this challenge, we propose to employ a \emph{hybrid} model for tracking combining the advantages of explicit and implicit representations.

\input{fig/convsurf/item.tex}
\paragraph{Hybrid tracking model}
The model we propose in this paper is a variant of a convolution surface~\cite{bloomenthal1991convolution}, and its fundamental building blocks are illustrated in \Figure{convsurf}. Such a construct is nothing but the zero iso-surface of the scalar function:
\begin{equation}
\phi(\mathbf{x}) = \min \int_{\mathbf{c} \in \skeleton} \mathcal{B}_{\mathbf{c}, r(\mathbf{c})}(\mathbf{x}) \: d\mathbf{c},
\label{eq:convsurf}
\end{equation}
where $\skeleton$ is a skeletal control mesh (a segment or a triangle in the simple examples of \Figure{convsurf}), and $\mathcal{B}$ is the implicit function of a sphere parameterized by its center $\mathbf{c}$ and radius $r$:
\begin{equation}
\mathcal{B}_{\mathbf{c}, r(\mathbf{c})}(\mathbf{x}) = \|\mathbf{x}-\mathbf{c}\|^2 - r(\mathbf{c})^2.
\end{equation}
The sphere centers $\mathbf{c}$ span the skeleton $\skeleton$, while the radii are a function of the position $\mathbf{c}$ within an element, linearly interpolated from values $r_*=r(c_*)$ specified on the skeletal mesh vertices $c_*$. This is indeed a \emph{hybrid} model, as \Eq{convsurf} defines an implicit surface $\surface = \{\mathbf{x} \in \mathbb{R}^n | \phi(\mathbf{x})=0 \}$, while the underlying skeleton $\skeleton$ is an explicit representation (i.e.\ a simplicial complex). We generalize this basic construct to devise a model suitable to represent a human hand; see \Figure{topology}.
\todo{Note that while the integral in \Eq{convsurf} might be difficult to evaluate, distances to $\surface$ can conveniently be computed by querying distances to the piecewise linear structures composing $\skeleton$; see \Figure{convsurf}.}

\input{fig/topology/item.tex}
\paragraph{Tracking and calibration with convolution models}
Our novel tracking model has two significant advantages. (1) Distance queries to $\surface$ can be executed by measuring the distance to the skeletal structure $\skeleton$. The number of elements in $\skeleton$ is significantly smaller~(\todo{25 in our model}) than the number of polygons in a typical triangular mesh surface representation~\cite{thiery2013sphere}. 
Therefore, distance queries can be performed efficiently using a brute force approach, which leads to a simple algorithm that is trivially parallelizable and executes at a fixed frame-rate. (2)~The parameterization of our hand model is compact, as we can generate a family of models by simply adjusting \emph{positions} and \emph{radii} of the control skeleton vertices $c_* \in \skeleton$. This allows adapting the model to the hand geometry of a specific user.

\paragraph{Contributions}
% Technical Contribution: What's the key technical idea to solve the problem? Why is it beautiful?
% Applications / Future Work: What will your solution enable? How does it project into the future? How will it inspire future work?
%In our research we identify a number of contributions:
%
The core contribution of this paper is to demonstrate that convolutional models provide superior hand tracking performance for single-view depth  sensors.  We introduce an optimization approach that allows adapting our tracking model to different human hands with a high level of accuracy. 
%In addition, instead of relying on an artist-built IK skeleton, we automatically identify the kinematic decomposition of motion from data.
The improved geometric fidelity compared to existing representations leads to quantifiable reductions in registration error and allows accurate tracking even for intricate hand poses and complex motion sequences that previous methods have difficulties with. 
At the same time, due to a very compact model representation and closed-form correspondences queries, our generative model retains high computational performance, leading to sustained tracking at 60 FPS.


%(1)~We demonstrate that convolutional models can be effectively employed for tracking of geometry in motion. 
%(2)~Amongst many possible variants, we identify an effective convolution surface  topology for hand-tracking. \AT{won't they us to compare against other topologies?} \MP{Yes, I would probably not state it like this. We have no evidence that we provide the best topology, we just found one that works. I would take this out of the contributions.}
%(3)~We demonstrate that the increased model accuracy does not aberrate tracking performance, leading to a 60 FPS tracking algorithm.
% (3) While any geometric model could be employed in tracking applications, it is imperative to determine whether a model is suitable for real-time tracking applications; we demonstrate this is the case by integrating our models in an open-source tracking system~\cite{tagliasacchi2015robust} and retaining 60 FPS tracking performance. 
%(4)~We introduce an optimization technique for convolution models that adapts a given template to a given user, and demonstrate how this results in substantial improvements in tracking precision.
%(5)~Rather than relying on a artist-built IK skeleton, we define an optimization problem to automatically identify the kinematic decomposition of motion from data.

%
%%
%\hspace{0in}
%%
%\MP{I would not list future work in the contributions section. It somewhat limits our contribution as we are already pointing to things that we did not do.}.
%%--- Areas of future work
%Our findings pave the way to a number of interesting venues for future works, including 
%(1)~the extension of our modeling framework to the capture of generic articulated geometry in motion, 
%(2)~the consolidation of optimization for modeling and tracking stages, 
%(3)~the generation of parameterizations, so to enable texturing and level-of-detail representations for convolution models and
%(4)~\todo{the possibility to automatically discover a tracking template}. \
%% 
%% \item Proposed a single optimization framework for modeling and tracking
%% \item Skinning. Display the texture on the model. For that a  parametrization is required. Potentially create ``bumps map'' to apply the errors from model fitting stage
%% \item Automatically identifies the degrees of freedom and axes of rotation from data

\paragraph{Overview}
The remainder of the paper is structured as follows: We first survey related work in Section~\ref{sec:related} and review in more detail the ICP-based generative approach for tracking that we employ in our system in \Section{tracking}.
We then introduce our convolution surface model that allows modeling human hands at high geometric fidelity for improved tracking accuracy. We show how our novel formulation enables efficient correspondence computation crucial for realtime tracking \AT{not true?}.
Section~\ref{sec:modeling} explains how we build our template model from 3D scans in an offline preprocess and how this template can be calibrated online towards a specific user based on RBGD sensor input only.
In Section~\ref{sec:results} we analyze the performance of our convolution surface model for realtime hand tracking and provide comparisons to alternative methods. We conclude with a discussion of current limitations and ideas for future work.



