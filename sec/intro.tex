% Problem Statement: What's the problem you want to solve?
% 
% Motivation: Why is this an interesting problem? Who cares about it? Why now? Why is it appropriate for the conference audience?
% 
% Research Gap, Novelty: Why is new research required? Why can the problem not be solved with existing methods? How does the proposed solution differ from and/or improve upon existing work?
% 
% Technical Contribution: What's the key technical idea to solve the problem? Why is it beautiful?
% 
% Applications / Future Work: What will your solution enable? How does it project into the future? How will it inspire future work?



% NOTE: the paragraph names can be removed later on
\section{Introduction}

%--- Why hand-tracking is fundamental (something abour AR/VR?)
% Hand tracking is a process of accurately reconstructing shape and articulation of human hands. It is a crucial component of natural human-computer interfaces and animation of humanoid avatars.
\TODO{In our world, our hands are our main mean of interaction, and with the advent of augmented and virtual reality experiences, there is a compelling need ...}
%--- Camera-based tracking & Physics
Accurate real-time hand tracking is therefore a fundamental technical challenge \todo{In AR and VR applications a 3D hand model can properly interact with 3D objects, establish a realistic contact and disappear behind them. Given that, the degree of immersion into virtual reality depends on whether a user sees own realistic hands (find a study mentioned by Leap Motion).} \todo{Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.}
\TODO{mention somewhere it's \emph{single} RGBD sensor acquisition}

\paragraph{Tracker: discriminative v.s. generative.}
Modern systems for real-time tracking \cite{sridhar2015fast,sharp2015accurate},  rely on a combination of \emph{discriminative} approaches like \cite{oberweger2015feedback}, and \emph{generative} approaches such as \cite{tagliasacchi2015robust}. The per-frame re-initialization of discriminative methods prevents error propagation by offering a continous recovery from tracking failure. As these discriminative models are learnt from data, they typically only estimate a coarse pose. Therefore, generative models are used to refine the estimate by aligning a geometric template of the user hand to the measured point cloud \AT{temporal?}. It is not surprising that the quality of the template directly affects the quality of pose refinement; see \Figure{teaser}. 
\TODO{mention no need to re-init $\gg$FPS?}.
% 
Therefore, the main goal of this paper is to explore novel tracking templates that strike an optimal \emph{balance} between accuracy and performance, that is, a model that is able to more accurately capture the user's geometry, while retaining the ability to answer registration queries in close form with very high efficiency. In \Figure{coarsemodel} and \todo{Video [00:00]} we illustrate the importance of employing a tracking template that strikes this delicate balance.

% \paragraph{Model calibration.}
% As generative models perform tracking by fitting a geometric model to what is measured by the sensor, our template should be able to represent well the observed data. However, even in modern trackers, the discrepancy between the optimal model pose given the data and the true hand pose can be significant. For example, the sources of discrepancy in \Figure{coarsemodel} include the incorrect length of fingers and the lack of the \todo{[pinky-ring]} degree of freedom. \todo{In the literature, the creation of user-specific models for tracking is referred to as \emph{calibration}.}

\input{fig/coarsemodel/item.tex}
\paragraph{Surface v.s. volumetric templates.}
In modern digital production representing objects by a piecewise linear meshing of their surface (i.e. triangular or quad meshes) is the de-facto standard. However, unlike volumetric models~\cite{bloomenthal1997book}, surface representations cannot efficiently answer queries such as the distance from the point to the object's boundary, or whether a point lies inside/outside the model~\cite[Ch.1]{botsch2010book}. In tracking applications these queries play a fundamental role, as the optimization attempts to find configurations where the average \emph{distance} from model to data is minimized. Similarly, a tracker should prevent the model from assuming implausible configurations, for example by preventing self-intersections as measured by inside/outside predicates. For all these reasons, volumetric models appear optimal for registration applications; indeed, recent compelling results in joint rigid registration and reconstruction~\cite{newcombe2011kinfu} as well as its recent non-rigid variant~\cite{newcombe2015dynfusion} leverage volumetric models. One important observations is that such techniques assume the frame-rate is high compared to user motion velocity, a condition that is surely not realizable in our setting. \AT{something about the fact that deforming a surface is easier than deforming a volume?} To tackle this challenge, in this paper we propose to employ a \emph{hybrid} model for tracking combining the advantages of surface and volumetric representations.

\input{fig/convsurf/item.tex}

\paragraph{Hybrid tracking model.}
The model we propose in this paper is a variant of a convolution surface~\cite{bloomenthal1991convolution}, and its fundamental building block is illustrated in \Figure{convsurf}. Such a construct is nothing but the zero iso-surface of the scalar function:
\begin{equation}
\phi(\mathbf{x}) = \min \int_{\mathbf{c} \in \mathcal{M}} \mathcal{B}_{\mathbf{c}, r(\mathbf{c})}(\mathbf{x}) \: d\mathbf{c},
\label{eq:convsurf}
\end{equation}
where $\mathcal{M}$ is a skeletal control mesh (a segment or a triangle with respect to the simple example in \Figure{convsurf}), and $\mathcal{B}$ is the implicit function of a sphere parameterized by its center $\mathbf{c}$ and radii $r$:
\begin{equation}
\mathcal{B}_{\mathbf{c}, r(\mathbf{c})}(\mathbf{x}) = \|\mathbf{x}-\mathbf{c}\|^2 - r(\mathbf{c})^2.
\end{equation}
The spheres centers $\mathbf{c}$ span the skeleton $\mathcal{M}$, while the radii is a function of the position $\mathbf{c}$ within an element, and more specifically, it is linearly interpolated from values specified on the skeletal mesh vertices $r_*=r(c_*)$. This is indeed a \emph{hybrid} model, as \Eq{convsurf} defines an implicit surface $\mathcal{S} = \{\mathbf{x} \in \mathbb{R}^n | \phi(\mathbf{x})=0 \}$, while the underlying skeleton $\mathcal{M}$ is an explicit representation (a piecewise-parameterized \todo{surface}). We generalize this basic construct to devise a model suitable to represent a human hand; see \Figure{topology}.
\todo{While the integral in \Eq{convsurf} might be difficult to evaluate, distances to $\mathcal{S}$ can conveniently be computed by querying distances to the piecewise linear structures composing $\mathcal{M}$; see \Figure{convsurf}.}

\input{fig/topology/item.tex}
\paragraph{Tracking and calibration with convolution models.}
Our novel tracking model has two significant advantages. (1) First of all, distance queries to $\surface$ can be executed by measuring the distance to the skeletal structure $\skeleton$. The number of elements in $\skeleton$ is significantly smaller (\todo{25} in our model) than the number of polygons in a typical triangular mesh representation of $\surface$~\cite{thiery2013sphere}. Therefore, not only our distance queries can be executed with great efficiently using a brute force approach, but this leads to an algorithm that is trivially parallelizable and that executes with a fixed frame-rate. (2)~Our hand model parameterization is also compact, as we can generate a family of models by simply adjusting \emph{positions} and \emph{radii} of the control skeleton vertices $c_* \in \skeleton$. A direct approach to building a calibrated model is to let the artist manually adjust these quantities; this process is known as  \emph{ZSphere~{\textcopyright}} modeling in the popular \emph{ZBrush~\textcopyright} 3D modeling software. \TODO{Something about why this makes the model efficient.} \TODO{Something about many recent SphereMeshes and ImplicitSkinning papers at SIGGRAPH?}

\input{fig/handmodels/item.tex}
\paragraph{Contributions.}
% Technical Contribution: What's the key technical idea to solve the problem? Why is it beautiful?
% Applications / Future Work: What will your solution enable? How does it project into the future? How will it inspire future work?
In our research we we identify a number of contributions:
(1)~We demonstrate that convolutional models can be effectively employed for tracking of geometry in motion. 
(2)~Amongst many possible variants, we identify an effective convolution surface  topology for hand-tracking. \AT{won't they us to compare against other topologies?}
(3)~We demonstrate that the increased model accuracy does not aberrate tracking performance, leading to a 60 FPS tracking algorithm.
% (3) While any geometric model could be employed in tracking applications, it is imperative to determine whether a model is suitable for real-time tracking applications; we demonstrate this is the case by integrating our models in an open-source tracking system~\cite{tagliasacchi2015robust} and retaining 60 FPS tracking performance. 
(4)~We introduce an optimization technique for convolution models that adapts a given template to a given user, and demonstrate how this results in substantial improvements in tracking precision.
(5)~Rather than relying on a artist-built IK skeleton, we define an optimization problem to automatically identify the kinematic decomposition of motion from data.
%
\hspace{0in}
% 
%--- Areas of future work
Our findings pave the way to a number of interesting venues for future works, including (1)~the extension of our modeling framework to the capture of generic articulated geometry in motion, (2)~the consolidation of optimization for modeling and tracking stages, 
(3)~the generation of parameterizations to enable texturing and level-of-detail representations, 
(4)~the possibility to 
% 



% \item Proposed a single optimization framework for modeling and tracking
% \item Skinning. Display the texture on the model. For that a  parametrization is required. Potentially create ``bumps map'' to apply the errors from model fitting stage
% \item Automatically identifies the degrees of freedom and axes of rotation from data
